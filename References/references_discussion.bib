@article{bouckaert_origin_2018,
	title = {The origin and expansion of {Pama-Nyungan} languages across {Australia}},
	volume = {2},
	rights = {2018 The Author(s)},
	issn = {2397-334X},
	doi = {10.1038/s41559-018-0489-3},
	pages = {741--749},
	number = {4},
	journaltitle = {Nature Ecology \& Evolution},
	author = {Bouckaert, Remco R. and Bowern, Claire and Atkinson, Quentin D.},
	date = {2018-04},
	langid = {english}
}

@article{sicoli_linguistic_2014,
	title = {Linguistic Phylogenies Support Back-Migration from Beringia to Asia},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091722},
	doi = {10.1371/journal.pone.0091722},
	abstract = {Recent arguments connecting Na-Dene languages of North America with Yeniseian languages of Siberia have been used to assert proof for the origin of Native Americans in central or western Asia. We apply phylogenetic methods to test support for this hypothesis against an alternative hypothesis that Yeniseian represents a back-migration to Asia from a Beringian ancestral population. We coded a linguistic dataset of typological features and used neighbor-joining network algorithms and Bayesian model comparison based on Bayes factors to test the fit between the data and the linguistic phylogenies modeling two dispersal hypotheses. Our results support that a Dene-Yeniseian connection more likely represents radiation out of Beringia with back-migration into central Asia than a migration from central or western Asia to North America.},
	pages = {e91722},
	number = {3},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Sicoli, Mark A. and Holton, Gary},
	urldate = {2020-08-21},
	date = {2014-03-12},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Historical linguistics, Phylogenetics, Sociolinguistics, Paleogenetics, Phylogenetic analysis, Languages, Asia, North America},
	file = {Full Text PDF:/Users/jaydencordes/Zotero/storage/SXEGB7MM/Sicoli and Holton - 2014 - Linguistic Phylogenies Support Back-Migration from.pdf:application/pdf;Snapshot:/Users/jaydencordes/Zotero/storage/HM9HCF93/article.html:text/html}
}

@article{yanovich_phylogenetic_2020,
	title = {Phylogenetic linguistic evidence and the Dene-Yeniseian homeland},
	url = {https://www.jbe-platform.com/content/journals/10.1075/dia.17038.yan},
	doi = {10.1075/dia.17038.yan},
	abstract = {Abstract Sicoli \&amp; Holton (2014) ({PLoS} {ONE} 9:3, e91722) use computational phylogenetics to argue that linguistic data from the putative, but likely, Dene-Yeniseian macro-family are better compatible with a homeland in Beringia (i.e., northeastern Siberia plus northwestern Alaska) than with one in central Siberia or deeper Asia. I show that a more careful examination of the data invalidates this conclusion: in fact, linguistic data do not support Beringia as the homeland. In the course of showing this, I discuss, without requiring a deep mathematical background, a number of methodological issues concerning computational phylogenetic analyses of linguistic data and drawing inferences from them. The aim is to contribute to making computational phylogenetics less of a black box for historical linguists. I conclude with a brief overview of the current evidence bearing on the Dene-Yeniseian homeland from linguistics, archaeology, folklore studies and genetics, and suggest current best practice for linguistic phylogenetics, the use of which would have helped to avoid some of the problems in Sicoli and Holton’s Dene-Yeniseian study, and in turn the percolation of those problems into subsequent synthetic interdisciplinary research.},
	author = {Yanovich, Igor},
	urldate = {2020-08-21},
	date = {2020-07-15},
	langid = {english},
	note = {Publisher: John Benjamins},
	file = {Snapshot:/Users/jaydencordes/Zotero/storage/9E4YI6JN/dia.17038.html:text/html}
}

@article{greenhill_evolutionary_2017,
	title = {Evolutionary dynamics of language systems},
	volume = {114},
	rights = {Copyright © 2017 the Author(s). Published by {PNAS}.. This is an open access article distributed under the {PNAS} license.},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1700388114},
	pages = {E8822--E8829},
	number = {42},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Greenhill, Simon J. and Wu, Chieh-Hsi and Hua, Xia and Dunn, Michael and Levinson, Stephen C. and Gray, Russell D.},
	date = {2017-10},
	langid = {english},
	pmid = {29073028},
	keywords = {linguistics, typology, language evolution, language dynamics, language phylogenies}
}

@article{clauset_power-law_2009,
	title = {Power-law distributions in empirical data},
	volume = {51},
	issn = {0036-1445},
	url = {http://epubs.siam.org/doi/abs/10.1137/070710111},
	doi = {10.1137/070710111},
	abstract = {Power-law distributions occur in many situations of scientific interest and have significant consequences for our understanding of natural and man-made phenomena. Unfortunately, the detection and characterization of power laws is complicated by the large fluctuations that occur in the tail of the distribution—the part of the distribution representing large but rare events—and by the difficulty of identifying the range over which power-law behavior holds. Commonly used methods for analyzing power-law data, such as least-squares fitting, can produce substantially inaccurate estimates of parameters for power-law distributions, and even in cases where such methods return accurate answers they are still unsatisfactory because they give no indication of whether the data obey a power law at all. Here we present a principled statistical framework for discerning and quantifying power-law behavior in empirical data. Our approach combines maximum-likelihood fitting methods with goodness-of-fit tests based on the Kolmogorov–Smirnov ({KS}) statistic and likelihood ratios. We evaluate the effectiveness of the approach with tests on synthetic data and give critical comparisons to previous approaches. We also apply the proposed methods to twenty-four real-world data sets from a range of different disciplines, each of which has been conjectured to follow a power-law distribution. In some cases we find these conjectures to be consistent with the data, while in others the power law is ruled out.},
	pages = {661--703},
	number = {4},
	journaltitle = {{SIAM} Review},
	shortjournal = {{SIAM} Rev.},
	author = {Clauset, A. and Shalizi, C. R. and Newman, M. E. J.},
	urldate = {2018-02-25},
	date = {2009-11-04},
	file = {Full Text PDF:/Users/jaydencordes/Zotero/storage/DGHTRNF5/Clauset et al. - 2009 - Power-Law Distributions in Empirical Data.pdf:application/pdf;Snapshot:/Users/jaydencordes/Zotero/storage/E39XM7KG/070710111.html:text/html}
}

@inproceedings{bowern_pama-nyungan_2015,
	location = {Leiden University, Leiden, Netherlands},
	title = {{Pama-Nyungan} phylogenetics and beyond [plenary address]},
	doi = {10.5281/zenodo.3032846},
	eventtitle = {Lorentz Center workshop on phylogenetic methods in linguistics},
	booktitle = {Lorentz Center workshop on phylogenetic methods in linguistics},
	author = {Bowern, Claire},
	date = {2015}
}

@article{baele_accurate_2013,
	title = {Accurate Model Selection of Relaxed Molecular Clocks in Bayesian Phylogenetics},
	volume = {30},
	issn = {0737-4038},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3548314/},
	doi = {10.1093/molbev/mss243},
	abstract = {Recent implementations of path sampling ({PS}) and stepping-stone sampling ({SS}) have been shown to outperform the harmonic mean estimator ({HME}) and a posterior simulation-based analog of Akaike’s information criterion through Markov chain Monte Carlo ({AICM}), in Bayesian model selection of demographic and molecular clock models. Almost simultaneously, a Bayesian model averaging approach was developed that avoids conditioning on a single model but averages over a set of relaxed clock models. This approach returns estimates of the posterior probability of each clock model through which one can estimate the Bayes factor in favor of the maximum a posteriori ({MAP}) clock model; however, this Bayes factor estimate may suffer when the posterior probability of the {MAP} model approaches 1. Here, we compare these two recent developments with the {HME}, stabilized/smoothed {HME} ({sHME}), and {AICM}, using both synthetic and empirical data. Our comparison shows reassuringly that {MAP} identification and its Bayes factor provide similar performance to {PS} and {SS} and that these approaches considerably outperform {HME}, {sHME}, and {AICM} in selecting the correct underlying clock model. We also illustrate the importance of using proper priors on a large set of empirical data sets.},
	pages = {239--243},
	number = {2},
	journaltitle = {Molecular Biology and Evolution},
	shortjournal = {Mol Biol Evol},
	author = {Baele, Guy and Li, Wai Lok Sibon and Drummond, Alexei J. and Suchard, Marc A. and Lemey, Philippe},
	urldate = {2020-06-14},
	date = {2013-02},
	pmid = {23090976},
	pmcid = {PMC3548314},
	file = {PubMed Central Full Text PDF:/Users/jaydencordes/Zotero/storage/97EV8ZIE/Baele et al. - 2013 - Accurate Model Selection of Relaxed Molecular Cloc.pdf:application/pdf}
}

@article{tambovtsev_phoneme_2007,
	title = {Phoneme frequencies follow a Yule distribution},
	volume = {4},
	url = {http://www.skase.sk/Volumes/JTL09/pdf_doc/1.pdf},
	abstract = {Frequency of occurrence of words in a language is well described by Zipf’s (1949) law. However, Zipf’s law does not well describe the distribution of the phonemes from which words are composed. Examination of frequency of occurrence in 95 languages shows
that phoneme frequencies are best described by an equation first developed by Yule (1924) that also describes the distribution of {DNA} codons. The Yule equation fits the distribution of phoneme frequencies better than the Zipf equation or equations proposed by Sigurd (1968) and Borodovsky and Gusein-Zade (1989).},
	number = {2},
	journaltitle = {{SKASE} Journal of Theoretical Linguistics (online)},
	author = {Tambovtsev, Yuri and Martindale, Colin},
	date = {2007},
	file = {Fulltext:/Users/jaydencordes/Zotero/storage/S3RSBA9I/Tambovtsev and Martindale - Phoneme Frequencies Follow a Yule Distribution.pdf:application/pdf;Snapshot:/Users/jaydencordes/Zotero/storage/E64HIHP6/Tambovtsev and Martindale - Phoneme Frequencies Follow a Yule Distribution.pdf:application/pdf}
}

@inproceedings{hollis_cape_2016,
	location = {Monash University, Caulfield, Australia},
	title = {The Cape York lexical records of Bruce Sommer},
	rights = {Creative Commons Attribution-{NonCommercial}-{NoDerivatives} 4.0 International License ({CC}-{BY}-{NC}-{ND})},
	doi = {https://dx.doi.org/10.6084/m9.figshare.4299377},
	eventtitle = {Australian Linguistic Society Annual Conference},
	author = {Hollis, Jordan and Richards, Genevieve C. and Macklin-Cordes, Jayden L. and Round, Erich R.},
	date = {2016-12-06},
	file = {The_Cape_York_lexical_records_of_Bruce_S.pdf:/Users/jaydencordes/Zotero/storage/IKR8TUEI/The_Cape_York_lexical_records_of_Bruce_S.pdf:application/pdf}
}

@article{greenhill_transnewguinea_2015,
	title = {{TransNewGuinea}.org: An online database of New Guinea languages},
	volume = {10},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141563},
	doi = {10.1371/journal.pone.0141563},
	shorttitle = {{TransNewGuinea}.org},
	pages = {e0141563},
	number = {10},
	journaltitle = {{PloS} One},
	author = {Greenhill, Simon J.},
	urldate = {2016-02-15},
	date = {2015}
}

@inproceedings{round_ausphon-lexicon_2017,
	location = {Poznań, Poland},
	title = {The {AusPhon}-Lexicon project: Two million normalized segments across 300 Australian languages},
	abstract = {http://wa.amu.edu.pl/plm\_old/2017/files/abstracts/{PLM}2017\_Abstract\_Round.{pdfWe} describe the logic, methods, tools and products of the {AusPhon}–Lexicon project, which at writing has
normalized 166 Australian language varieties (1.2million segments) and aims at 290–320 varieties
({\textasciitilde}2.1million segments).
Materials: Input data is printed and electronic vocabularies, including all modern data of Bowern’s(2016)
{CHIRILA} database, plus {\textasciitilde}100 additional varieties.
Processes: Data is scrubbed; graphemically tokenized (additional output: language grapheme token-izers),
phonemicized (additional output: customizable language phonemicizers, which can then phonemicize textual
material for example), and post-produced with a variety of mark-up, e.g. for duplicates, names, ideophones.
Tools \& workflow: We use existing and customized tools in R, and extensive ‘human computing’
(Michelucci and Dickinson 2016): alternating between machine and humans, each doing what they excel at.
Specific innovations include entropy-based junk filtering during scrubbing, and visualiz-ation-based errorchecking at multiple points (additional output: language data visualizations).
Logic of the process: While it may seem that the task is merely to make an ‘electronic version’ of the
lexicons of a continent, we argue that the task is deeply more complicated. Effective normalization across
300 languages has demanded meta-analysis of disparate analytical traditions spanning half a century, in order
to understand why previous analyses are how they are, and therefore what implications will accompany
decisions to normalize one way or another. We discuss in particular the bleeding of phonotactic, areal–
historical, and theory-based concerns into the analysis of inventories, and the responses/solutions we’ve
identified, which where possible enhance rather than degrade information relative to the un-normalized
original.
Resulting representations: The most salient outputs are normalized segmental strings. Yet to be meaningful,
these are networked to annotations that link decisions back to original sources, and record all steps in the
ingest–scrub–tokenize–phonemicize trail. We consider the result to be not a ‘database’ containing answers to
pre-existing questions, but a ‘data warehouse’(Cooper 2014) to be engaged with through queries. Thus,
whereas a traditional typological project might produce after much labour a single database on consonant
clusters (Hamilton 1996), we can create a new database — on clusters, vowel harmony, position
neutralization, {OCP} effects, etc. — with a simple query.
Data querying: To this end, we use tools for customizable, on-the-fly featurization; a ‘phonex’ extended
regular expression language; and n-gram extraction to create character-based datasets for use, e.g. in
phylogenetic phono¬tactic research(Macklin-Cordes and Round 2015). A layer of ‘archi-phonemicization’ or
‘Firthianization’ scripts handle positional neutralization, which can otherwise lead to misleading disparities
even in an otherwise well-normalized segmental representation.
Constraints: Sister projects were run to gauge the prospects of integrating sub-phonemic information. We
find the mining of information on allophony from descriptive grammars to be largely infeasible
unfortunately, given results from both (i) surveys of what gets reported, and (ii) ground-truthing such reports
against instrumental phonetic study. Nevertheless, there are exceptions. Highly salient features such as
nasal/lateral pre-stopping and major allophonic place-of-articulation differences may be viable for
integration (as an overlay) into this kind of segmental dataset.
Quantitative analysis: Finally, we illustrate the extraordinary potential of such data for linguistic research,
showing that the Australian dental/palatal contrast, long thought to be thoroughly areally distributed(Dixon
1970), in fact contains ample phylogenetic signal throughout Pama-Nyungan.},
	eventtitle = {47th Poznań Linguistic Meeting ({PLM}2017)},
	author = {Round, Erich R.},
	date = {2017-09-18},
	file = {Round - 2017 - The AusPhon-Lexicon project Two million normalize.pdf:/Users/jaydencordes/Zotero/storage/XV4S9M3E/Round - 2017 - The AusPhon-Lexicon project Two million normalize.pdf:application/pdf}
}

@inproceedings{round_automated_2020,
	location = {Marseille, France},
	title = {Automated Parsing of Interlinear Glossed Text from Page Images of Grammatical Descriptions},
	isbn = {979-10-95546-34-4},
	url = {https://www.aclweb.org/anthology/2020.lrec-1.351},
	abstract = {Linguists seek insight from all human languages, however accessing information from most of the full store of extant global linguistic descriptions is not easy. One of the most common kinds of information that linguists have documented is vernacular sentences, as recorded in descriptive grammars. Typically these sentences are formatted as interlinear glossed text ({IGT}). Most descriptive grammars, however, exist only as hardcopy or scanned pdf documents. Consequently, parsing {IGTs} in scanned grammars is a priority, in order to significantly increase the volume of documented linguistic information that is readily accessible. Here we demonstrate fundamental viability for a technology that can assist in making a large number of linguistic data sources machine readable: the automated identification and parsing of interlinear glossed text from scanned page images. For example, we attain high median precision and recall ({\textgreater}0.95) in the identification of examples sentences in {IGT} format. Our results will be of interest to those who are keen to see more of the existing documentation of human language, especially for less-resourced and endangered languages, become more readily accessible.},
	pages = {2878--2883},
	booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference},
	publisher = {European Language Resources Association},
	author = {Round, Erich and Ellison, Mark and Macklin-Cordes, Jayden and Beniamine, Sacha},
	date = {2020-05}
}

@inproceedings{salesky_corpus_2020,
	location = {Online},
	title = {A Corpus for Large-Scale Phonetic Typology},
	url = {https://www.aclweb.org/anthology/2020.acl-main.415},
	doi = {10.18653/v1/2020.acl-main.415},
	abstract = {A major hurdle in data-driven research on typology is having sufficient data in many languages to draw meaningful conclusions. We present {VoxClamantis} v1.0, the first large-scale corpus for phonetic typology, with aligned segments and estimated phoneme-level labels in 690 readings spanning 635 languages, along with acoustic-phonetic measures of vowels and sibilants. Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages. However, it is non-trivial and computationally intensive to obtain such alignments for hundreds of languages, many of which have few to no resources presently available. We describe the methodology to create our corpus, discuss caveats with current methods and their impact on the utility of this data, and illustrate possible research directions through a series of case studies on the 48 highest-quality readings. Our corpus and scripts are publicly available for non-commercial use at https://voxclamantisproject.github.io.},
	eventtitle = {{ACL} 2020},
	pages = {4526--4546},
	booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher = {Association for Computational Linguistics},
	author = {Salesky, Elizabeth and Chodroff, Eleanor and Pimentel, Tiago and Wiesner, Matthew and Cotterell, Ryan and Black, Alan W and Eisner, Jason},
	urldate = {2020-09-30},
	date = {2020-07},
	file = {Full Text PDF:/Users/jaydencordes/Zotero/storage/5RCX7DSL/Salesky et al. - 2020 - A Corpus for Large-Scale Phonetic Typology.pdf:application/pdf}
}

@article{hassler_inferring_2020,
	title = {Inferring Phenotypic Trait Evolution on Large Trees With Many Incomplete Measurements},
	issn = {0162-1459},
	url = {https://amstat.tandfonline.com/doi/full/10.1080/01621459.2020.1799812},
	doi = {10.1080/01621459.2020.1799812},
	abstract = {Comparative biologists are often interested in inferring covariation between multiple biological traits sampled across numerous related taxa. To properly study these relationships, we must control for the shared evolutionary history of the taxa to avoid spurious inference. An additional challenge arises as obtaining a full suite of measurements becomes increasingly difficult with increasing taxa. This generally necessitates data imputation or integration, and existing control techniques typically scale poorly as the number of taxa increases. We propose an inference technique that integrates out missing measurements analytically and scales linearly with the number of taxa by using a post-order traversal algorithm under a multivariate Brownian diffusion ({MBD}) model to characterize trait evolution. We further exploit this technique to extend the {MBD} model to account for sampling error or nonheritable residual variance. We test these methods to examine mammalian life history traits, prokaryotic genomic and phenotypic traits, and {HIV} infection traits. We find computational efficiency increases that top two orders-of-magnitude over current best practices. While we focus on the utility of this algorithm in phylogenetic comparative methods, our approach generalizes to solve long-standing challenges in computing the likelihood for matrix-normal and multivariate normal distributions with missing data at scale. Supplementary materials for this article are available online.},
	pages = {1--15},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {null},
	author = {Hassler, Gabriel and Tolkoff, Max R. and Allen, William L. and Ho, Lam Si Tung and Lemey, Philippe and Suchard, Marc A.},
	urldate = {2020-09-30},
	date = {2020-08-13},
	note = {Publisher: Taylor \& Francis}
}

@article{tolkoff_phylogenetic_2018,
	title = {Phylogenetic Factor Analysis},
	volume = {67},
	issn = {1063-5157},
	url = {http://academic.oup.com/sysbio/article/67/3/384/4076231},
	doi = {10.1093/sysbio/syx066},
	abstract = {Abstract.  Phylogenetic comparative methods explore the relationships between quantitative traits adjusting for shared evolutionary history. This adjustment oft},
	pages = {384--399},
	number = {3},
	journaltitle = {Systematic Biology},
	shortjournal = {Syst Biol},
	author = {Tolkoff, Max R. and Alfaro, Michael E. and Baele, Guy and Lemey, Philippe and Suchard, Marc A.},
	urldate = {2020-09-30},
	date = {2018-05-01},
	langid = {english},
	note = {Publisher: Oxford Academic},
	file = {Full Text PDF:/Users/jaydencordes/Zotero/storage/ETHHMLHQ/Tolkoff et al. - 2018 - Phylogenetic Factor Analysis.pdf:application/pdf;Snapshot:/Users/jaydencordes/Zotero/storage/P6STC4QP/4076231.html:text/html}
}

@inproceedings{macklin-cordes_phylogeny_2018,
	location = {University of South Australia, Adelaide},
	title = {Phylogeny in phonotactics: A multivariate approach for stronger historical signal},
	rights = {All rights reserved},
	eventtitle = {Australian Linguistics Society Annual Conference},
	author = {Macklin-Cordes, Jayden L. and Round, Erich R.},
	date = {2018-12-12}
}